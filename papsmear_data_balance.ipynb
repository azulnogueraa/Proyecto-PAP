{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "HSIL: 1089\n",
      "LSIL: 870\n",
      "Negative: 4338\n",
      "ASC-H: 592\n",
      "ASC-US: 387\n",
      "SCC: 102\n",
      "\n",
      "Validación:\n",
      "HSIL: 273\n",
      "LSIL: 218\n",
      "Negative: 1085\n",
      "ASC-H: 148\n",
      "ASC-US: 97\n",
      "SCC: 26\n",
      "\n",
      "Prueba:\n",
      "HSIL: 341\n",
      "LSIL: 272\n",
      "Negative: 1356\n",
      "ASC-H: 185\n",
      "ASC-US: 122\n",
      "SCC: 33\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def contar_imagenes(ruta):\n",
    "    for categoria in os.listdir(ruta):\n",
    "        path = os.path.join(ruta, categoria)\n",
    "        count = len([nombre for nombre in os.listdir(path) if os.path.isfile(os.path.join(path, nombre))])\n",
    "        print(f'{categoria}: {count}')\n",
    "\n",
    "ruta_train = 'data_split/train'\n",
    "ruta_val = 'data_split/val'\n",
    "ruta_test = 'data_split/test'\n",
    "\n",
    "print(\"Entrenamiento:\")\n",
    "contar_imagenes(ruta_train)\n",
    "\n",
    "print(\"\\nValidación:\")\n",
    "contar_imagenes(ruta_val)\n",
    "\n",
    "print(\"\\nPrueba:\")\n",
    "contar_imagenes(ruta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanceando conjunto de entrenamiento...\n",
      "Reducción de HSIL a 800 imágenes por undersampling.\n",
      "Reducción de LSIL a 800 imágenes por undersampling.\n",
      "Reducción de Negative a 800 imágenes por undersampling.\n",
      "Aumento de ASC-H a 800 imágenes por oversampling.\n",
      "Aumento de ASC-US a 800 imágenes por oversampling.\n",
      "Aumento de SCC a 800 imágenes por oversampling.\n",
      "\n",
      "Balanceando conjunto de validación...\n",
      "Reducción de HSIL a 200 imágenes por undersampling.\n",
      "Reducción de LSIL a 200 imágenes por undersampling.\n",
      "Reducción de Negative a 200 imágenes por undersampling.\n",
      "Aumento de ASC-H a 200 imágenes por oversampling.\n",
      "Aumento de ASC-US a 200 imágenes por oversampling.\n",
      "Aumento de SCC a 200 imágenes por oversampling.\n",
      "\n",
      "Balanceando conjunto de prueba...\n",
      "Reducción de HSIL a 300 imágenes por undersampling.\n",
      "Aumento de LSIL a 300 imágenes por oversampling.\n",
      "Reducción de Negative a 300 imágenes por undersampling.\n",
      "Aumento de ASC-H a 300 imágenes por oversampling.\n",
      "Aumento de ASC-US a 300 imágenes por oversampling.\n",
      "Aumento de SCC a 300 imágenes por oversampling.\n",
      "\n",
      "Distribución de imágenes después del balanceo:\n",
      "Entrenamiento: {'HSIL': 800, 'LSIL': 800, 'Negative': 800, 'ASC-H': 800, 'ASC-US': 800, 'SCC': 800}\n",
      "Validación: {'HSIL': 200, 'LSIL': 200, 'Negative': 200, 'ASC-H': 200, 'ASC-US': 200, 'SCC': 200}\n",
      "Prueba: {'HSIL': 300, 'LSIL': 300, 'Negative': 300, 'ASC-H': 300, 'ASC-US': 300, 'SCC': 300}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directorios de datos\n",
    "train_dir = 'data_split/train'\n",
    "val_dir = 'data_split/val'\n",
    "test_dir = 'data_split/test'\n",
    "\n",
    "# Configuración de balanceo\n",
    "target_train_count = 800  # Cantidad objetivo para el conjunto de entrenamiento\n",
    "target_val_count = 200    # Cantidad objetivo para el conjunto de validación\n",
    "target_test_count = 300   # Cantidad objetivo para el conjunto de prueba\n",
    "\n",
    "# Función para balancear clases\n",
    "def balance_classes(data_dir, target_count, datagen):\n",
    "    classes = os.listdir(data_dir)\n",
    "    \n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(data_dir, cls)\n",
    "        images = os.listdir(class_dir)\n",
    "        num_images = len(images)\n",
    "        \n",
    "        # Undersampling si la clase tiene más muestras que el objetivo\n",
    "        if num_images > target_count:\n",
    "            images_to_remove = sample(images, num_images - target_count)\n",
    "            for img in images_to_remove:\n",
    "                os.remove(os.path.join(class_dir, img))\n",
    "            print(f\"Reducción de {cls} a {target_count} imágenes por undersampling.\")\n",
    "        \n",
    "        # Oversampling si la clase tiene menos muestras que el objetivo\n",
    "        elif num_images < target_count:\n",
    "            images_to_add = target_count - num_images\n",
    "            while images_to_add > 0:\n",
    "                img = sample(images, 1)[0]\n",
    "                img_data = np.expand_dims(plt.imread(os.path.join(class_dir, img)), 0)\n",
    "                aug_iter = datagen.flow(img_data, batch_size=1)\n",
    "                aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "                \n",
    "                new_img_name = f\"aug_{images_to_add}_{os.path.basename(img)}\"\n",
    "                new_img_path = os.path.join(class_dir, new_img_name)\n",
    "                plt.imsave(new_img_path, aug_img)\n",
    "                \n",
    "                images_to_add -= 1\n",
    "            print(f\"Aumento de {cls} a {target_count} imágenes por oversampling.\")\n",
    "\n",
    "# Instancia del generador de aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Balancear conjunto de entrenamiento\n",
    "print(\"Balanceando conjunto de entrenamiento...\")\n",
    "balance_classes(train_dir, target_train_count, datagen)\n",
    "\n",
    "# Balancear conjunto de validación\n",
    "print(\"\\nBalanceando conjunto de validación...\")\n",
    "balance_classes(val_dir, target_val_count, datagen)\n",
    "\n",
    "# Balancear conjunto de prueba\n",
    "print(\"\\nBalanceando conjunto de prueba...\")\n",
    "balance_classes(test_dir, target_test_count, datagen)\n",
    "\n",
    "# Verificación de los resultados\n",
    "def count_images_in_directory(directory):\n",
    "    return {cls: len(os.listdir(os.path.join(directory, cls))) for cls in os.listdir(directory)}\n",
    "\n",
    "print(\"\\nDistribución de imágenes después del balanceo:\")\n",
    "print(\"Entrenamiento:\", count_images_in_directory(train_dir))\n",
    "print(\"Validación:\", count_images_in_directory(val_dir))\n",
    "print(\"Prueba:\", count_images_in_directory(test_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
